"""
heatingdata_pipeline.py

End-to-end portfolio pipeline that replicates your RapidMiner workflow:
- Load the full dataset from /data
- EDA stats + missingness + basic distributions
- Heating_Type segment summary (aggregate)
- Correlation matrix + heatmap image (oil drivers)
- Offer_Accepted label creation (rule-based prototype) if missing
- Decision Tree model + train/test evaluation + confusion matrix image
- Score ALL customers + confidence columns
- Export offer assignments + targeted campaign targets (no "None") to CSV + Excel

Repo-friendly structure:
heatingdata/
  data/
    home_heating_marketing_portfolio.xlsx
  src/
    heatingdata_pipeline.py
  output/
    figures/
"""

from __future__ import annotations

from pathlib import Path
import warnings

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
)

import matplotlib.pyplot as plt


# -----------------------------
# 0) Paths (run from anywhere)
# -----------------------------
ROOT = Path(__file__).resolve().parents[1]  # project root: heatingdata/
DATA_PATH = ROOT / "data" / "home_heating_marketing_portfolio.xlsx"

OUT = ROOT / "output"
FIG = OUT / "figures"
OUT.mkdir(parents=True, exist_ok=True)
FIG.mkdir(parents=True, exist_ok=True)


# -----------------------------
# Helpers
# -----------------------------
def load_dataset(path: Path) -> pd.DataFrame:
    """Load Excel or CSV with reasonable defaults."""
    if not path.exists():
        raise FileNotFoundError(f"Data file not found: {path}")

    suffix = path.suffix.lower()
    if suffix in {".xlsx", ".xlsm", ".xls"}:
        return pd.read_excel(path)
    if suffix == ".csv":
        # sep=None lets pandas sniff comma vs semicolon, etc.
        return pd.read_csv(path, sep=None, engine="python")
    raise ValueError(f"Unsupported file type: {suffix}")


def safe_mean(series: pd.Series) -> float:
    """Mean that won't crash if the series isn't numeric."""
    return pd.to_numeric(series, errors="coerce").mean()


def assign_offer_rule_based(row: pd.Series) -> str:
    """
    Prototype offer logic (mirrors your RapidMiner rule intent).
    NOTE: This is a *simulated label* for portfolio demonstration.
    """
    heating = row.get("Heating_Type")
    demand = row.get("Oil_Demand_Score", 0)
    ineff = row.get("Inefficiency_Score", 0)
    age = row.get("Home_Age", 0)
    ins = row.get("Insulation_Rating", 0)

    # Bundle: Oil + high demand + high inefficiency
    if heating == "Oil" and demand > 0.70 and ineff > 0.65:
        return "Bundle"

    # OilPlan: Oil + meaningful demand
    if heating == "Oil" and demand > 0.60:
        return "OilPlan"

    # Insulation: high inefficiency OR older home + poor insulation signal
    if (ineff > 0.70) or (age > 40 and ins >= 8):
        return "Insulation"

    return "None"


def save_corr_heatmap(corr: pd.DataFrame, out_path: Path, title: str) -> None:
    """Save a simple correlation heatmap using matplotlib only."""
    plt.figure(figsize=(10, 7))
    plt.imshow(corr.values, aspect="auto")
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha="right")
    plt.yticks(range(len(corr.index)), corr.index)
    plt.colorbar()
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_path, dpi=200)
    plt.close()


# -----------------------------
# Main pipeline
# -----------------------------
def main() -> None:
    warnings.filterwarnings("ignore")

    print("Project root:", ROOT)
    print("Loading data from:", DATA_PATH)
    print("Data exists?", DATA_PATH.exists())

    # 1) Load
    df = load_dataset(DATA_PATH)
    print("\nLoaded shape:", df.shape)

    # Basic checks
    (OUT / "README_outputs.txt").write_text(
        "This folder contains outputs generated by heatingdata_pipeline.py\n"
    )

    # 2) EDA: numeric stats + missingness + key categorical counts
    numeric_stats = df.describe(include=[np.number]).T
    numeric_stats.to_csv(OUT / "home_heating_numeric_stats.csv")

    missing = df.isna().sum().sort_values(ascending=False)
    missing.to_csv(OUT / "missing_values_summary.csv")

    if "Heating_Type" in df.columns:
        df["Heating_Type"].value_counts(dropna=False).to_csv(
            OUT / "heating_type_counts.csv"
        )

    # Optional: distributions (simple hist grid)
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if numeric_cols:
        df[numeric_cols].hist(figsize=(14, 10))
        plt.tight_layout()
        plt.savefig(FIG / "feature_histograms.png", dpi=200)
        plt.close()

    # 3) Segment summary by Heating_Type (Aggregate)
    required_cols = {
        "Customer_ID",
        "Heating_Type",
        "Heating_Oil_Used",
        "Home_Size",
        "Home_Age",
        "Insulation_Rating",
        "Outdoor_Temp",
        "Climate_Zone",
        "Tenure_Months",
        "Auto_Delivery",
        "Service_Plan",
        "Oil_Margin_Per_Gallon",
    }
    missing_required = sorted([c for c in required_cols if c not in df.columns])
    if missing_required:
        print("\nWARNING: Missing columns for full segment summary:", missing_required)

    if "Heating_Type" in df.columns:
        seg = (
            df.groupby("Heating_Type", dropna=False)
            .agg(
                Customers=("Customer_ID", "count") if "Customer_ID" in df.columns else ("Heating_Type", "size"),
                Avg_Oil_Used=("Heating_Oil_Used", safe_mean) if "Heating_Oil_Used" in df.columns else ("Heating_Type", "size"),
                Avg_Home_Size=("Home_Size", safe_mean) if "Home_Size" in df.columns else ("Heating_Type", "size"),
                Avg_Home_Age=("Home_Age", safe_mean) if "Home_Age" in df.columns else ("Heating_Type", "size"),
                Avg_Insulation=("Insulation_Rating", safe_mean) if "Insulation_Rating" in df.columns else ("Heating_Type", "size"),
                Avg_Outdoor_Temp=("Outdoor_Temp", safe_mean) if "Outdoor_Temp" in df.columns else ("Heating_Type", "size"),
                Avg_Climate_Zone=("Climate_Zone", safe_mean) if "Climate_Zone" in df.columns else ("Heating_Type", "size"),
                Avg_Tenure=("Tenure_Months", safe_mean) if "Tenure_Months" in df.columns else ("Heating_Type", "size"),
                Pct_Auto_Delivery=("Auto_Delivery", safe_mean) if "Auto_Delivery" in df.columns else ("Heating_Type", "size"),
                Pct_Service_Plan=("Service_Plan", safe_mean) if "Service_Plan" in df.columns else ("Heating_Type", "size"),
                Avg_Margin=("Oil_Margin_Per_Gallon", safe_mean) if "Oil_Margin_Per_Gallon" in df.columns else ("Heating_Type", "size"),
            )
            .reset_index()
        )

        seg.to_excel(OUT / "heat_type_segment_summary.xlsx", index=False)
        seg.to_csv(OUT / "heat_type_segment_summary.csv", index=False)

    # 4) Correlation matrix (oil drivers)
    corr_cols = [
        "Insulation_Rating",
        "Outdoor_Temp",
        "Home_Age",
        "Home_Size",
        "Heating_Oil_Used",
        "Climate_Zone",
        "Tenure_Months",
        "Auto_Delivery",
        "Service_Plan",
        "Oil_Margin_Per_Gallon",
    ]
    corr_cols = [c for c in corr_cols if c in df.columns]
    if corr_cols:
        corr = df[corr_cols].corr(numeric_only=True)
        corr.to_csv(OUT / "oil_drivers_corr_matrix.csv")
        save_corr_heatmap(
            corr,
            FIG / "oil_drivers_corr_matrix.png",
            title="Oil Drivers Correlation Matrix",
        )

    # 5) Create Offer_Accepted label (if missing)
    if "Offer_Accepted" not in df.columns:
        df["Offer_Accepted"] = df.apply(assign_offer_rule_based, axis=1)

    # 6) Model: Decision Tree to predict Offer_Accepted
    features = [
        "Heating_Type",
        "Insulation_Rating",
        "Outdoor_Temp",
        "Home_Age",
        "Home_Size",
        "Heating_Oil_Used",
        "Climate_Zone",
        "Tenure_Months",
        "Auto_Delivery",
        "Service_Plan",
        "Oil_Margin_Per_Gallon",
        "Oil_Demand_Score",
        "Inefficiency_Score",
    ]
    features = [f for f in features if f in df.columns]
    if not features:
        raise RuntimeError("No features found to train the model. Check your column names.")

    X = df[features].copy()
    y = df["Offer_Accepted"].copy()

    # One-hot encode Heating_Type if present
    if "Heating_Type" in X.columns:
        X = pd.get_dummies(X, columns=["Heating_Type"], drop_first=False)

    # Train/test split (70/30), stratified
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.30,
        random_state=42,
        stratify=y,
    )

    model = DecisionTreeClassifier(max_depth=6, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    print("\nModel accuracy:", round(acc, 4))
    print("\nClassification report:\n", report)

    # Save evaluation text
    (OUT / "model_classification_report.txt").write_text(
        f"Accuracy: {acc:.4f}\n\n{report}\n"
    )

    # Save confusion matrix image
    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    disp.plot(values_format="d")
    plt.title(f"Confusion Matrix (Accuracy={acc:.2%})")
    plt.tight_layout()
    plt.savefig(FIG / "offer_confusion_matrix.png", dpi=200)
    plt.close()

    # Save tree image
    plt.figure(figsize=(20, 10))
    plot_tree(
        model,
        feature_names=X.columns,
        class_names=model.classes_,
        filled=True,
        fontsize=8,
    )
    plt.title("Decision Tree: Offer Recommendation")
    plt.tight_layout()
    plt.savefig(FIG / "decision_tree_offer_model.png", dpi=200)
    plt.close()

    # 7) Score ALL customers + confidence columns (like RapidMiner)
    proba = model.predict_proba(X)
    classes = model.classes_
    pred_all = model.predict(X)

    scored = df.copy()
    scored["Recommended_Offer"] = pred_all

    for i, c in enumerate(classes):
        scored[f"confidence({c})"] = proba[:, i]

    # Export offer assignments (all customers)
    export_cols = ["Customer_ID", "Offer_Accepted", "Recommended_Offer"] + [f"confidence({c})" for c in classes]
    # Add a few context fields if present
    context_cols = ["Heating_Type", "Home_Age", "Insulation_Rating", "Climate_Zone"]
    export_cols += [c for c in context_cols if c in scored.columns]
    export_cols = [c for c in export_cols if c in scored.columns]

    offer_assignments = scored[export_cols].copy()
    offer_assignments.to_csv(OUT / "offer_assignments.csv", index=False)
    offer_assignments.to_excel(OUT / "offer_assignments.xlsx", index=False)

    # Export targeted campaign (exclude None)
    targeted = scored[scored["Recommended_Offer"] != "None"].copy()
    targeted_cols = ["Customer_ID", "Recommended_Offer"] + [f"confidence({c})" for c in classes]
    targeted_cols += [c for c in context_cols if c in targeted.columns]
    targeted_cols = [c for c in targeted_cols if c in targeted.columns]

    targeted_campaign = targeted[targeted_cols].copy()
    targeted_campaign.to_csv(OUT / "targeted_campaign_targets.csv", index=False)
    targeted_campaign.to_excel(OUT / "targeted_campaign_targets.xlsx", index=False)

    print("\nSaved outputs to:", OUT)
    print("Saved figures to:", FIG)
    print("\nKey files:")
    print("-", OUT / "offer_assignments.xlsx")
    print("-", OUT / "targeted_campaign_targets.xlsx")
    print("-", FIG / "offer_confusion_matrix.png")
    print("-", FIG / "oil_drivers_corr_matrix.png")


if __name__ == "__main__":
    main()
